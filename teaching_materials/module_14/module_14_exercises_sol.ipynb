{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for Session 14: Text as Data\n",
    "\n",
    "In session 14 you will learn how to preprocess text data and structure it, so we can exploit the information in the texts. \n",
    "\n",
    "You will work on a larger exercise where you will use the tools you learn. In the exercise you will use the logistic regression model, which is fitted on the movie review dataset in the slides to predict sentiments on a completely different dataset: \n",
    "\n",
    "- The dataset contains tweets about US airlines. You can read more about it here: https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment?resource=download\n",
    "- Each tweet has been classified as positive, negative or neutral, which makes it possible for us to compare the predictions from our logistic regression model with the actual sentiments.\n",
    "\n",
    "The purpose of this exercise is to learn the pitfalls of fitting a model to one kind of text data, and then use the model to predict sentiments of another kind of text data (*cross-domain evaluation*). I.e., we will investigate how *generalizable* our model is.\n",
    "\n",
    "- Spoiler: The words in the tweets convey a completely different meaning than the words in the movie reviews, so our movie review logistic regression model is not good at predicting sentiments in tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the logistic regression model on the movie review data\n",
    "\n",
    "Before we can get started, you need to run the code below that fits a logistic regression model on the movie review data.\n",
    "\n",
    "We will then use that model to predict sentiments in the twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8', sep=';')\n",
    "\n",
    "# Clean reviews\n",
    "def cleaner(document):\n",
    "    document = document.lower() #To lower case\n",
    "    document = re.sub(r'<[^>]*>', ' ', document) #Remove HTML\n",
    "    document = re.sub(r'[^\\w\\s]','', document) #Remove non-alphanumeric characters\n",
    "    return document\n",
    "\n",
    "df['review'] = df['review'].apply(cleaner)\n",
    "\n",
    "# Load train and test sets to different dataframes\n",
    "df_train = df[df.set==\"train\"]\n",
    "df_test = df[df.set==\"test\"]\n",
    "\n",
    "# Sort the data randomly to mix positive and negative reviews\n",
    "np.random.seed(0)\n",
    "df_train = df.reindex(np.random.permutation(df_train.index))\n",
    "df_test = df.reindex(np.random.permutation(df_test.index))\n",
    "\n",
    "# Take out X and Y variable\n",
    "x_train = df_train['review'].values\n",
    "x_test = df_test['review'].values\n",
    "y_train = df_train['sentiment'].values\n",
    "y_test = df_test['sentiment'].values\n",
    "\n",
    "# Make our bag of words\n",
    "tfidf = TfidfVectorizer()\n",
    "x_train_bag = tfidf.fit_transform(x_train)\n",
    "\n",
    "# Fit the model\n",
    "lr_reviews = LogisticRegression(random_state=0) #Text classifier\n",
    "lr_reviews.fit(x_train_bag,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jHLDsg-Cvo8o"
   },
   "source": [
    "# Part 1: Cross-domain evaluation of a logistic regression model fitted on movie review data\n",
    "\n",
    "First load the twitter data, which you can find on github under module 14:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(\"AirlineTweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, change the sentiment to \"positive\" if the sentiment is labelled \"neutral\" to have only two categories. In the same time store the sentiments in a list for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiments = [0 if i==\"negative\" else 1 for i in tweet_df.airline_sentiment]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to watch the video below before moving on to the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('piawPVa2Zjk', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.1:** Preprocess the twitter texts. You should at least do the following:\n",
    "> - Make all letters lower case\n",
    "> - Remove mentions; i.e. \"@user\". You can do this with regex.\n",
    "> - Can you think of other things to clean? Take a look at some of the tweets to look for other unnecessary stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "def cleaner(document):\n",
    "    document = document.lower() #To lower case\n",
    "    document = re.sub(r'@\\w+','', document) #Remove mentions\n",
    "    return document\n",
    "\n",
    "tweet_df['text'] = tweet_df['text'].apply(cleaner)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to watch the video below before moving on to the next exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('UtyYHIDwN8A', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.2:** Make your bag of words from the tweets using the tf-idf vectorizer (\"tfidf\") previously fitted on the movie review data. \n",
    "\n",
    "> *Hint:* You should use the `transform()` method instead of the `fit_transform()` because you have already fitted the vocabulary of the bag of words on the movie review data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "tweets_bag = tfidf.transform(tweet_df['text'].values)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to watch the video below before moving on to the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('qzSm3rSx2Iw', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.3:** Use the trained logistic regression model from above (\"lr_reviews\") to predict the sentiment of the tweets.\n",
    "> - Report testing accuracy\n",
    "\n",
    "> *Hint:* Use the \"tweet_sentiments\" list from above to compare the predicted sentiments and the actual sentiments and compute the testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy = 0.6471311475409836\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "preds = lr_reviews.predict(tweets_bag)\n",
    "print(\"Testing accuracy =\",np.mean([(preds==tweet_sentiments)]))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.4:** How well does the logistic regression model from the review data perform in this other domain?\n",
    "> - Why do you think it does not perform as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer here\n",
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "The model performs poorly compared to before: Testing accuracy of 64.7 % compared to 88.4 % in the review data.\n",
    "\n",
    "Potential reasons:\n",
    "- There is an unequal distribution of positive and negative examples in the airline dataset (more negative), while in the review dataset, the distribution was equal\n",
    "- The terms that were the most important counting towards a positive sentiment in the review dataset, i.e. the ones with high coefficients, are not the ones that are important in the twitter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.5:** Now train a new logstic regression model on the twitter data:\n",
    "> 1. Fit a new bag of words on the twitter texts\n",
    "> 2. Fit a logistic regression model on the twitter bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Make our bag of words\n",
    "tfidf_tweet = TfidfVectorizer()\n",
    "tweets_new_bag = tfidf_tweet.fit_transform(tweet_df['text'].values)\n",
    "\n",
    "# Fit the model\n",
    "lr_tweets = LogisticRegression(random_state=0) #Text classifier\n",
    "lr_tweets.fit(tweets_new_bag, tweet_sentiments)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 14.1.6:** What are the most important features/words (high and low coefficients) in the new model? \n",
    "> - Do they differ from the most important features from the old model?\n",
    "> - What does this mean for the models' ability to generalize to new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                           0\n",
      "thank               7.178505\n",
      "thanks              6.335961\n",
      "great               4.359550\n",
      "love                4.037155\n",
      "awesome             3.623015\n",
      "amazing             3.488303\n",
      "worries             3.103664\n",
      "best                3.101206\n",
      "kudos               2.521151\n",
      "hi                  2.242853\n",
      "good                2.166981\n",
      "follow              2.104571\n",
      "excellent           2.099351\n",
      "destinationdragons  2.097787\n",
      "appreciate          2.046885\n",
      "possible            1.836600\n",
      "know                1.777430\n",
      "favorite            1.727311\n",
      "following           1.723798\n",
      "few                 1.712300\n",
      "\n",
      "                  0\n",
      "not       -5.357811\n",
      "no        -5.138165\n",
      "delayed   -4.850456\n",
      "hours     -4.668565\n",
      "worst     -4.436032\n",
      "hold      -4.316067\n",
      "cancelled -3.773514\n",
      "why       -3.660970\n",
      "nothing   -3.573728\n",
      "hour      -3.380091\n",
      "delay     -3.252315\n",
      "luggage   -3.248405\n",
      "your      -3.130182\n",
      "because   -3.095372\n",
      "lost      -3.021391\n",
      "late      -2.982668\n",
      "stuck     -2.907334\n",
      "again     -2.837497\n",
      "rude      -2.825324\n",
      "hrs       -2.822516\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Make our bag of words\n",
    "tweets_features = ['_'.join(s.split()) for s in tfidf_tweet.get_feature_names_out()]\n",
    "tweets_coefficients = lr_tweets.coef_\n",
    "tweets_coefs_df = pd.DataFrame.from_records(tweets_coefficients, columns=tweets_features)\n",
    "\n",
    "# Most important (positive and negative) features:\n",
    "print()\n",
    "print(tweets_coefs_df.T.sort_values(by=[0], ascending=False).head(20))\n",
    "print()\n",
    "print(tweets_coefs_df.T.sort_values(by=[0], ascending=True).head(20))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "The take-away point is, that the logistic regression model does not generalize well to data from another domain. \n",
    "\n",
    "Words that are important for identifying overall sentiment may differ a lot with respect to what the sentiment is directed towards as well as the platform on which it is written, affecting the language people use. \n",
    "\n",
    "Therefore, you have to be careful when choosing your data and be aware of potential limitations and biases that follows from your data or from models that are pre-trained. \n",
    "\n",
    "Often, training data such as the movie review data is too \"clean\" and the performance you may achieve with such data is much better than most practical implementations may achieve. For example in real life there is more than just positive and negative sentiment, and the sentiment classes may not be evenly distributed."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Introduction to Social Data Science: Text as Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
